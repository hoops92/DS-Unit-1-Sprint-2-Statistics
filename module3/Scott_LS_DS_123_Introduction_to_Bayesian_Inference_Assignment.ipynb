{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scott_LS_DS_123_Introduction_to_Bayesian_Inference_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoops92/DS-Unit-1-Sprint-2-Statistics/blob/master/module3/Scott_LS_DS_123_Introduction_to_Bayesian_Inference_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 123\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - Code it up!\n",
        "\n",
        "We used pure math to apply Bayes Theorem to drug tests. Now write Python code to reproduce the results! This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up.\n",
        "\n",
        "Specific goals/targets:\n",
        "\n",
        "### 1) Write a function \n",
        "\n",
        "`def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate):` \n",
        "\n",
        "You should only truly need these two values in order to apply Bayes Theorem. In this example, imagine that individuals are taking a breathalyzer test with an 8% false positive rate, a 100% true positive rate, and that our prior belief about drunk driving in the population is 1/1000. \n",
        " - What is the probability that a person is drunk after one positive breathalyzer test?\n",
        " - What is the probability that a person is drunk after two positive breathalyzer tests?\n",
        " - How many positive breathalyzer tests are needed in order to have a probability that's greater than 95% that a person is drunk beyond the legal limit?\n",
        "\n",
        "### 2) Explore `scipy.stats.bayes_mvs`  \n",
        "Read its documentation, and experiment with it on data you've tested in other ways earlier this week.\n",
        " - Create a visualization comparing the results of a Bayesian approach to a traditional/frequentist approach. (with a large sample size they should look close to identical, however, take this opportunity to practice visualizing condfidence intervals in general. The following are some potential ways that you could visualize confidence intervals on your graph:\n",
        "  - [Matplotlib Error Bars](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html)\n",
        "  - [Seaborn barplot with error bars](https://seaborn.pydata.org/generated/seaborn.barplot.html)\n",
        "  - [Vertical ines to show bounds of confidence interval](https://www.simplypsychology.org/confidence-interval.jpg)\n",
        "  - [Confidence Intervals on Box Plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.axes.Axes.boxplot.html)\n",
        "\n",
        "### 3) In your own words, summarize the difference between Bayesian and Frequentist statistics\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate):\n",
        "  #prob_of_true_positive\n",
        "  p1 = 1 - false_positive_rate\n",
        "\n",
        "  #prob_of_any_random_person_being_user\n",
        "  p2 = prob_drunk_prior\n",
        "\n",
        "  #prob_of_false_positive\n",
        "  p3 = false_positive_rate\n",
        "\n",
        "  #prob_of_any_random_person_being_non_user\n",
        "  p4 = 1 - prob_drunk_prior\n",
        "\n",
        "  bayes = (p1*p2) / ((p1*p2) + (p3*p4))\n",
        "\n",
        "  return bayes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCon5tsOb_Dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "24a91fe5-4867-4ad5-cd91-bfa526b256c3"
      },
      "source": [
        "#Breathalizer test/drug-screen after one time\n",
        "bayes_percent = prob_drunk_given_positive(0.001, 0.08)\n",
        "print(bayes_percent)\n",
        "\n",
        "#Breathalizer test/drug-screen two times\n",
        "bayes_percent2 = prob_drunk_given_positive(bayes_percent, 0.08)\n",
        "print(bayes_percent2)\n",
        "\n",
        "#Breathalizer test/drug-screen after three times\n",
        "bayes_percent3 = prob_drunk_given_positive(bayes_percent2, 0.08)\n",
        "print(bayes_percent3)\n",
        "\n",
        "#Breathalizer test/drug-screen after four times\n",
        "bayes_percent4 = prob_drunk_given_positive(bayes_percent3, 0.08)\n",
        "print(bayes_percent4)\n",
        "\n",
        "#Breathlizer test/drug-screen after five times\n",
        "bayes_percent5 = prob_drunk_given_positive(bayes_percent4, 0.08)\n",
        "print(bayes_percent5)\n",
        "\n",
        "# CONCLUSION:\n",
        "#THE FOURTH BREATHALIZER/DRUG-SCREEN GETS VERY CLOSE TO 95%\n",
        "#BUT WOULD ONLY BE CONSIDERED 95% IF YOU ROUND UP\n",
        "#SO A FIFTH TIME IS REQUIRED TO SUCCESSFULLY SURPASS THE 95TH ACCURACY PERCENTILE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.011380504700643244\n",
            "0.11690607734806628\n",
            "0.6035517634803313\n",
            "0.9459680554381814\n",
            "0.9950577515521439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOwZccFNcFjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "688dc5a8-e50b-426f-c824-2621bf1dccc5"
      },
      "source": [
        "from scipy import stats\n",
        "help(stats.bayes_mvs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function bayes_mvs in module scipy.stats.morestats:\n",
            "\n",
            "bayes_mvs(data, alpha=0.9)\n",
            "    Bayesian confidence intervals for the mean, var, and std.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : array_like\n",
            "        Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.\n",
            "        Requires 2 or more data points.\n",
            "    alpha : float, optional\n",
            "        Probability that the returned confidence interval contains\n",
            "        the true parameter.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    mean_cntr, var_cntr, std_cntr : tuple\n",
            "        The three results are for the mean, variance and standard deviation,\n",
            "        respectively.  Each result is a tuple of the form::\n",
            "    \n",
            "            (center, (lower, upper))\n",
            "    \n",
            "        with `center` the mean of the conditional pdf of the value given the\n",
            "        data, and `(lower, upper)` a confidence interval, centered on the\n",
            "        median, containing the estimate to a probability ``alpha``.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    mvsdist\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Each tuple of mean, variance, and standard deviation estimates represent\n",
            "    the (center, (lower, upper)) with center the mean of the conditional pdf\n",
            "    of the value given the data and (lower, upper) is a confidence interval\n",
            "    centered on the median, containing the estimate to a probability\n",
            "    ``alpha``.\n",
            "    \n",
            "    Converts data to 1-D and assumes all data has the same mean and variance.\n",
            "    Uses Jeffrey's prior for variance and std.\n",
            "    \n",
            "    Equivalent to ``tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))``\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
            "    standard-deviation from data\", https://scholarsarchive.byu.edu/facpub/278,\n",
            "    2006.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    First a basic example to demonstrate the outputs:\n",
            "    \n",
            "    >>> from scipy import stats\n",
            "    >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
            "    >>> mean, var, std = stats.bayes_mvs(data)\n",
            "    >>> mean\n",
            "    Mean(statistic=9.0, minmax=(7.103650222612533, 10.896349777387467))\n",
            "    >>> var\n",
            "    Variance(statistic=10.0, minmax=(3.176724206..., 24.45910382...))\n",
            "    >>> std\n",
            "    Std_dev(statistic=2.9724954732045084, minmax=(1.7823367265645143, 4.945614605014631))\n",
            "    \n",
            "    Now we generate some normally distributed random data, and get estimates of\n",
            "    mean and standard deviation with 95% confidence intervals for those\n",
            "    estimates:\n",
            "    \n",
            "    >>> n_samples = 100000\n",
            "    >>> data = stats.norm.rvs(size=n_samples)\n",
            "    >>> res_mean, res_var, res_std = stats.bayes_mvs(data, alpha=0.95)\n",
            "    \n",
            "    >>> import matplotlib.pyplot as plt\n",
            "    >>> fig = plt.figure()\n",
            "    >>> ax = fig.add_subplot(111)\n",
            "    >>> ax.hist(data, bins=100, density=True, label='Histogram of data')\n",
            "    >>> ax.vlines(res_mean.statistic, 0, 0.5, colors='r', label='Estimated mean')\n",
            "    >>> ax.axvspan(res_mean.minmax[0],res_mean.minmax[1], facecolor='r',\n",
            "    ...            alpha=0.2, label=r'Estimated mean (95% limits)')\n",
            "    >>> ax.vlines(res_std.statistic, 0, 0.5, colors='g', label='Estimated scale')\n",
            "    >>> ax.axvspan(res_std.minmax[0],res_std.minmax[1], facecolor='g', alpha=0.2,\n",
            "    ...            label=r'Estimated scale (95% limits)')\n",
            "    \n",
            "    >>> ax.legend(fontsize=10)\n",
            "    >>> ax.set_xlim([-4, 4])\n",
            "    >>> ax.set_ylim([0, 0.5])\n",
            "    >>> plt.show()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d32draacPA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cda2fec9-6cdd-4605-87f0-8b9fa8493e0f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "reefs = pd.read_csv('http://www.zernach.com/wp-content/uploads/2019/10/CoralBleaching.csv')\n",
        "\n",
        "reefs_no_unknowns = reefs[(reefs['SEVERITY_CODE']==0) | (reefs['SEVERITY_CODE']==1) | \n",
        "      (reefs['SEVERITY_CODE']==2) | (reefs['SEVERITY_CODE']==3)]\n",
        "\n",
        "stats.bayes_mvs(reefs_no_unknowns['SEVERITY_CODE'], alpha=.95)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=1.3563840448987774, minmax=(1.3248516674305078, 1.387916422367047)),\n",
              " Variance(statistic=1.2913107172118607, minmax=(1.2406364949039308, 1.3419849395197907)),\n",
              " Std_dev(statistic=1.1363585337435806, minmax=(1.1140617758088334, 1.158655291678328)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45zGQ_BTcQ5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confidence_int(input_data, confidence_level):\n",
        "  data = np.array(input_data.dropna()) #make sure the input data has no NaN values, and is in an array format\n",
        "  mean = np.mean(data) #mean of the points in the dataset\n",
        "  n = len(data) #number of data points in the dataset\n",
        "  sem = stats.sem(data) #SEM â€” the standard error of the mean (or standard error of measurement)\n",
        "  margin_of_error = sem * stats.t.ppf(((1 + confidence_level)/2.0), (n - 1))\n",
        "  lower_bound = mean - margin_of_error\n",
        "  upper_bound = mean + margin_of_error\n",
        "  print(' Mean: ', mean, '\\n Lower Bound: ', lower_bound, '\\n Upper Bound: ', upper_bound)\n",
        "  return (mean, lower_bound, upper_bound)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6562WnBcUi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f0ebf1ac-0285-4a02-e61f-7dd471217a9c"
      },
      "source": [
        "(mean, lower_bound, upper_bound) = confidence_int(reefs_no_unknowns['SEVERITY_CODE'], .95)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Mean:  1.3563840448987774 \n",
            " Lower Bound:  1.3248408526736621 \n",
            " Upper Bound:  1.3879272371238927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hq8Nsn9cXYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "49973bba-8126-4fa8-b2f2-f2c46c746b19"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "spread = 4\n",
        "data = (spread, mean, upper_bound, lower_bound)\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.set_title('Basic Plot')\n",
        "ax1.boxplot(data);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF6HXly3XN2liAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B8BjsXocb1Y",
        "colab_type": "text"
      },
      "source": [
        "### 3\n",
        "\n",
        "For small sample sizes, it is more beneficial to use Bayesian statistics, in order to ensure validity and accuracy of the test. One should adapt their prior knowledge and beliefs based on the results.\n",
        "\n",
        "If the sample size is large, it's more beneficial to use Frequenist statistics.\n",
        "A frequentists runs a test a several times, and lets the data speak for itself, but sometimes that's just not possible to go about this way of measuring statistics because of financial or other constraints related to producing reliable stattistics.\n",
        "organized datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgWjp3PQ3Sq",
        "colab_type": "text"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgHqmYIQ9qn",
        "colab_type": "text"
      },
      "source": [
        "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
        "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP7Jv1XvwtkX",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Go back and study the content from Modules 1 & 2 to make sure that you're really comfortable with them.\n",
        "- Apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective\n",
        "- Check out [PyMC3](https://docs.pymc.io/) (note this goes beyond hypothesis tests into modeling) - read the guides and work through some examples\n",
        "- Take PyMC3 further - see if you can build something with it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDi0eFr1x-v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}